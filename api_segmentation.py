from fastapi import FastAPI, UploadFile, File
from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image
import io
from pathlib import Path
from tensorflow import keras
import os
import gdown
import matplotlib.pyplot as plt
import cv2
from fastapi.responses import Response

# ID du fichier Google Drive (remplacez par votre propre ID)
FILE_ID = "12vreJSXI9P0lpwF0gWnoKuG0T6RJnVFK"
MODEL_DIR = "model"
MODEL_PATH = os.path.join(MODEL_DIR, "unet_model.h5")

def download_model_from_drive():
    """T√©l√©charge le mod√®le depuis Google Drive si non pr√©sent localement."""
    # üîπ Cr√©er le dossier `model/` s'il n'existe pas
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)
        print(f"üìÅ Dossier cr√©√© : {MODEL_DIR}")

    if not os.path.exists(MODEL_PATH):
        print("üîÑ T√©l√©chargement du mod√®le depuis Google Drive...")
        gdown.download(f"https://drive.google.com/uc?id={FILE_ID}", MODEL_PATH, quiet=False)
        print("‚úÖ Mod√®le t√©l√©charg√© avec succ√®s !")
    else:
        print("‚úÖ Mod√®le d√©j√† pr√©sent localement.")

# Ex√©cuter le t√©l√©chargement au d√©marrage
download_model_from_drive()

# Charger le mod√®le U-Net 
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "model" / "unet_model.h5"
model = load_model(MODEL_PATH)


app = FastAPI()

# Charger le mod√®le de segmentation
model = keras.models.load_model(MODEL_PATH, compile=False)
print("‚úÖ Mod√®le charg√© avec succ√®s !")
def preprocess_image(image_bytes):
    """Pr√©traitement de l'image avant pr√©diction"""
    image = Image.open(io.BytesIO(image_bytes)).resize((256, 256))
    image = np.array(image) / 255.0  # Normalisation
    
    print(f"üîé Valeurs min/max de l‚Äôimage: {image.min()} - {image.max()}")  # üî• Debug
    
    image = np.expand_dims(image, axis=0)  # Ajouter une dimension batch
    return image



@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    """Endpoint de pr√©diction"""
    image = await file.read()
    processed_image = preprocess_image(image)
    prediction = model.predict(processed_image)
    
    # Obtenir les classes
    mask = np.argmax(prediction, axis=-1)[0]
    
    # Debugging : afficher les valeurs uniques et leur distribution
    unique_values = np.unique(mask)
    print(f"Valeurs uniques dans le masque: {unique_values}")
    print(f"Nombre de pixels par classe: {[np.sum(mask == val) for val in unique_values]}")
    
    # Si le masque n'a qu'une seule valeur, essayez d'utiliser les probabilit√©s brutes
    if len(unique_values) <= 1:
        print("‚ö†Ô∏è Masque uniforme d√©tect√© ! Utilisation des probabilit√©s brutes.")
        # Prendre le canal avec la plus haute probabilit√© pour chaque pixel
        mask = prediction[0, :, :, 0] * 255  # Supposons que le premier canal est significatif
    
    # Normaliser pour s'assurer que les valeurs sont visibles
    # √âtirer l'histogramme pour utiliser toute la plage 0-255
    if mask.max() > mask.min():  # √âviter la division par z√©ro
        mask_normalized = ((mask - mask.min()) / (mask.max() - mask.min()) * 255).astype(np.uint8)
    else:
        mask_normalized = np.zeros_like(mask, dtype=np.uint8)
    
    # Appliquer une colormap pour rendre les diff√©rences plus visibles
    # Convertir d'abord en image √† 3 canaux RGB
    colored_mask = cv2.applyColorMap(mask_normalized, cv2.COLORMAP_JET)
    
    # Conversion en image
    _, buffer = cv2.imencode(".png", colored_mask)
    
    return Response(content=buffer.tobytes(), media_type="image/png")



